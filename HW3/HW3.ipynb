{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c3782f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n",
      "TensorFlow 2.0 Hello World\r\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "msg = tf.constant('TensorFlow 2.0 Hello World')\n",
    "tf.print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c058acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adagrad\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65eff46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0084ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fedic\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X, y = load_boston(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a543c278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 13)\n",
      "(379,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1866e5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127, 13)\n",
      "(127,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62fbd115",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(13,)),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(), \n",
    "    loss='mse', \n",
    "    metrics=[RootMeanSquaredError()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bc4008c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 2ms/step - loss: 291.1481 - root_mean_squared_error: 17.0631\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 85.3879 - root_mean_squared_error: 9.2406\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 74.4856 - root_mean_squared_error: 8.6305\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 64.9552 - root_mean_squared_error: 8.0595\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 64.5057 - root_mean_squared_error: 8.0315\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 76.7862 - root_mean_squared_error: 8.7628\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 78.2731 - root_mean_squared_error: 8.8472\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 62.1551 - root_mean_squared_error: 7.8839\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 56.2010 - root_mean_squared_error: 7.4967\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 56.2034 - root_mean_squared_error: 7.4969\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 57.4627 - root_mean_squared_error: 7.5804\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 59.6828 - root_mean_squared_error: 7.7255\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 57.6432 - root_mean_squared_error: 7.5923\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 53.9948 - root_mean_squared_error: 7.3481\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 53.0228 - root_mean_squared_error: 7.2817\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 45.8187 - root_mean_squared_error: 6.7690\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 49.7094 - root_mean_squared_error: 7.0505\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 43.5098 - root_mean_squared_error: 6.5962\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 42.4309 - root_mean_squared_error: 6.5139\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 41.7819 - root_mean_squared_error: 6.4639\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 41.3991 - root_mean_squared_error: 6.4342\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 39.3844 - root_mean_squared_error: 6.2757\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 43.4334 - root_mean_squared_error: 6.5904\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 49.9692 - root_mean_squared_error: 7.0689\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 40.9136 - root_mean_squared_error: 6.3964\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 48.3709 - root_mean_squared_error: 6.9549\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 43.3558 - root_mean_squared_error: 6.5845\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 38.0224 - root_mean_squared_error: 6.1662\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 41.0088 - root_mean_squared_error: 6.4038\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 43.0843 - root_mean_squared_error: 6.5639\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 33.0821 - root_mean_squared_error: 5.7517\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 33.0209 - root_mean_squared_error: 5.7464\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 30.7161 - root_mean_squared_error: 5.5422\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 34.6708 - root_mean_squared_error: 5.8882\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 35.5943 - root_mean_squared_error: 5.9661\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.1689 - root_mean_squared_error: 5.6718\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 28.8003 - root_mean_squared_error: 5.3666\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 34.8364 - root_mean_squared_error: 5.9022\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 29.5017 - root_mean_squared_error: 5.4315\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 38.1299 - root_mean_squared_error: 6.1749\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 30.4230 - root_mean_squared_error: 5.5157\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.9625 - root_mean_squared_error: 5.2880\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 35.3214 - root_mean_squared_error: 5.9432\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.3998 - root_mean_squared_error: 5.6921\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 30.7221 - root_mean_squared_error: 5.5427\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 31.8470 - root_mean_squared_error: 5.6433\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 34.6840 - root_mean_squared_error: 5.8893\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 35.2677 - root_mean_squared_error: 5.9387\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 31.0760 - root_mean_squared_error: 5.5746\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.7538 - root_mean_squared_error: 5.2682\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.8110 - root_mean_squared_error: 5.0805\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.1847 - root_mean_squared_error: 5.1171\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 35.2583 - root_mean_squared_error: 5.9379\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 28.9056 - root_mean_squared_error: 5.3764\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 28.8039 - root_mean_squared_error: 5.3669\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.6375 - root_mean_squared_error: 5.1612\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.7271 - root_mean_squared_error: 4.8710\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.8704 - root_mean_squared_error: 4.7823\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.5771 - root_mean_squared_error: 4.9575\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 31.2979 - root_mean_squared_error: 5.5944\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.9800 - root_mean_squared_error: 4.9980\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.3106 - root_mean_squared_error: 4.8281\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.6700 - root_mean_squared_error: 4.7613\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 30.0060 - root_mean_squared_error: 5.4778\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.5501 - root_mean_squared_error: 4.9548\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.9364 - root_mean_squared_error: 4.8925\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.5363 - root_mean_squared_error: 4.9534\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.8393 - root_mean_squared_error: 4.6733\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.0036 - root_mean_squared_error: 4.5830\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.9214 - root_mean_squared_error: 4.5740\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 19.9829 - root_mean_squared_error: 4.4702\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.1677 - root_mean_squared_error: 4.7083\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.2577 - root_mean_squared_error: 4.6106\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.1656 - root_mean_squared_error: 4.8131\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.2588 - root_mean_squared_error: 5.0258\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.7625 - root_mean_squared_error: 4.6650\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.8202 - root_mean_squared_error: 4.8806\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.1541 - root_mean_squared_error: 4.4893\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.1658 - root_mean_squared_error: 4.3779\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.1912 - root_mean_squared_error: 4.2651\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.6162 - root_mean_squared_error: 4.3147\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.5470 - root_mean_squared_error: 4.5329\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.8561 - root_mean_squared_error: 4.2256\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.5403 - root_mean_squared_error: 3.9421\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.8843 - root_mean_squared_error: 3.9855\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.1130 - root_mean_squared_error: 4.3718\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.8352 - root_mean_squared_error: 4.3400\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.7222 - root_mean_squared_error: 4.7668\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 26.6199 - root_mean_squared_error: 5.1594\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 16.2310 - root_mean_squared_error: 4.0288\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.0031 - root_mean_squared_error: 4.5829\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.4386 - root_mean_squared_error: 5.1418\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.7251 - root_mean_squared_error: 4.5525\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 21.3869 - root_mean_squared_error: 4.6246\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 16.6513 - root_mean_squared_error: 4.0806\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 29.0562 - root_mean_squared_error: 5.3904\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.1145 - root_mean_squared_error: 5.1102\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 19.0698 - root_mean_squared_error: 4.3669\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.5090 - root_mean_squared_error: 4.3022\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.8753 - root_mean_squared_error: 3.8569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2772391a460>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "707ba84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[21.220531],\n",
       "       [24.021233],\n",
       "       [16.993698],\n",
       "       [11.07815 ],\n",
       "       [13.604284]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y = model.predict(X_test)\n",
    "predict_y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e884d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.8, 21.7, 15.2, 13.5,  9.7])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "763e3476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.667615557710132"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(y_test, predict_y).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c937e7f1",
   "metadata": {},
   "source": [
    "Выше был построен пример модели для предсказания задачи регрессии.\n",
    "\n",
    "Попробуем поменять некоторые параметры этой сети и запишем результаты работы, а после сравним их.\n",
    "\n",
    "Все модели будут обучаться на 100 эпохах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62a7fc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сюда будем записывать основные параметры модели\n",
    "params = []\n",
    "\n",
    "# итоговая метрика для модели на тетсовых данных\n",
    "metrics = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa87a67f",
   "metadata": {},
   "source": [
    "Для начала построим сеть с одним скрытым слоем с 256ю нейронами и функцией активации relu, первый слой будет иметь 128 нейровнов и функцию активации linear и выходной слой с одним нейроном без функции активации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "baadae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "params.append({\"layers\": 1, \"hiddenLayersNeurons\": 256, \"hiddenLayersFunc\": \"relu\", \"optimizer\": \"Adam\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ad8f235",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(128, activation='linear', input_shape=(13,)),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(), \n",
    "    loss='mse', \n",
    "    metrics=[RootMeanSquaredError()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d2b45e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1291.9730 - root_mean_squared_error: 35.9440\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 317.6756 - root_mean_squared_error: 17.8235\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 146.9256 - root_mean_squared_error: 12.1213\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 82.9933 - root_mean_squared_error: 9.1101\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 65.5039 - root_mean_squared_error: 8.0935\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 63.8666 - root_mean_squared_error: 7.9917\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 77.4082 - root_mean_squared_error: 8.7982\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 69.5210 - root_mean_squared_error: 8.3379\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 57.7111 - root_mean_squared_error: 7.5968\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 52.0395 - root_mean_squared_error: 7.2138\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 53.9003 - root_mean_squared_error: 7.3417\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 51.2897 - root_mean_squared_error: 7.1617\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 59.3120 - root_mean_squared_error: 7.7014\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 53.6034 - root_mean_squared_error: 7.3214\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 48.8472 - root_mean_squared_error: 6.9891\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 49.5060 - root_mean_squared_error: 7.0360\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 52.5446 - root_mean_squared_error: 7.2488\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 52.9085 - root_mean_squared_error: 7.2738\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 45.7763 - root_mean_squared_error: 6.7658\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 53.1188 - root_mean_squared_error: 7.2883\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 70.9312 - root_mean_squared_error: 8.4221\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 48.1366 - root_mean_squared_error: 6.9381\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 45.3036 - root_mean_squared_error: 6.7308\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 46.1557 - root_mean_squared_error: 6.7938\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 51.3812 - root_mean_squared_error: 7.1681\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 44.3543 - root_mean_squared_error: 6.6599\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 48.2902 - root_mean_squared_error: 6.9491\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 39.4315 - root_mean_squared_error: 6.2795\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 39.2317 - root_mean_squared_error: 6.2635\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 59.2493 - root_mean_squared_error: 7.6974\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 42.8955 - root_mean_squared_error: 6.5495\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 47.9790 - root_mean_squared_error: 6.9267\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 44.6867 - root_mean_squared_error: 6.6848\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 41.7102 - root_mean_squared_error: 6.4583\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 49.5435 - root_mean_squared_error: 7.0387\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 47.6752 - root_mean_squared_error: 6.9047\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 47.5322 - root_mean_squared_error: 6.8944\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 45.7755 - root_mean_squared_error: 6.7658\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 58.5228 - root_mean_squared_error: 7.6500\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 39.6377 - root_mean_squared_error: 6.2958\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 41.3420 - root_mean_squared_error: 6.4298\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 35.3869 - root_mean_squared_error: 5.9487\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 46.9033 - root_mean_squared_error: 6.8486\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 46.7498 - root_mean_squared_error: 6.8374\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 39.6709 - root_mean_squared_error: 6.2985\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 35.7542 - root_mean_squared_error: 5.9795\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 39.2239 - root_mean_squared_error: 6.2629\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 34.0312 - root_mean_squared_error: 5.8336\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 38.3563 - root_mean_squared_error: 6.1932\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 44.6034 - root_mean_squared_error: 6.6786\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 53.7450 - root_mean_squared_error: 7.3311\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 70.7311 - root_mean_squared_error: 8.4102\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 47.5956 - root_mean_squared_error: 6.8990\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 40.7061 - root_mean_squared_error: 6.3801\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 44.0468 - root_mean_squared_error: 6.6368\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 36.2395 - root_mean_squared_error: 6.0199\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 34.3984 - root_mean_squared_error: 5.8650\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 38.9504 - root_mean_squared_error: 6.2410\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 35.2133 - root_mean_squared_error: 5.9341\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 34.4987 - root_mean_squared_error: 5.8736\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 46.2234 - root_mean_squared_error: 6.7988\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 36.4005 - root_mean_squared_error: 6.0333\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 42.4330 - root_mean_squared_error: 6.5141\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9432 - root_mean_squared_error: 5.7396\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 34.1163 - root_mean_squared_error: 5.8409\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 37.1940 - root_mean_squared_error: 6.0987\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 32.5003 - root_mean_squared_error: 5.7009\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 33.7768 - root_mean_squared_error: 5.8118\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 37.0400 - root_mean_squared_error: 6.0861\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 33.7887 - root_mean_squared_error: 5.8128\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 39.2394 - root_mean_squared_error: 6.2641\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 69.8607 - root_mean_squared_error: 8.3583\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 91.3914 - root_mean_squared_error: 9.5599\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 64.1141 - root_mean_squared_error: 8.0071\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 37.2436 - root_mean_squared_error: 6.1028\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 44.1845 - root_mean_squared_error: 6.6471\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 43.1465 - root_mean_squared_error: 6.5686\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 46.9554 - root_mean_squared_error: 6.8524\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 52.7384 - root_mean_squared_error: 7.2621\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 58.9879 - root_mean_squared_error: 7.6804\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 55.4212 - root_mean_squared_error: 7.4445\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 42.2392 - root_mean_squared_error: 6.4992\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 41.6380 - root_mean_squared_error: 6.4527\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 35.0210 - root_mean_squared_error: 5.9179\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 42.8466 - root_mean_squared_error: 6.5457\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 29.9686 - root_mean_squared_error: 5.4744\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 30.2656 - root_mean_squared_error: 5.5014\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 41.1350 - root_mean_squared_error: 6.4137\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 51.4633 - root_mean_squared_error: 7.1738\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 45.6846 - root_mean_squared_error: 6.7590\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 58.2444 - root_mean_squared_error: 7.6318\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 37.7548 - root_mean_squared_error: 6.1445\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 34.4790 - root_mean_squared_error: 5.8719\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 30.8340 - root_mean_squared_error: 5.5528\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 35.7719 - root_mean_squared_error: 5.9810\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 30.3456 - root_mean_squared_error: 5.5087\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.8150 - root_mean_squared_error: 5.2740\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 29.8115 - root_mean_squared_error: 5.4600\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 34.1125 - root_mean_squared_error: 5.8406\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 49.6626 - root_mean_squared_error: 7.0472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27724b8cdf0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71c4ee1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "[[17.744942]\n",
      " [21.857151]\n",
      " [15.796645]\n",
      " [ 5.085099]\n",
      " [ 9.727954]]\n",
      "[24.8 21.7 15.2 13.5  9.7]\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(X_test)\n",
    "print(y_predict[:5])\n",
    "print(y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "965c25db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.77192442137926\n"
     ]
    }
   ],
   "source": [
    "metric = rmse(y_test, y_predict).numpy()\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3c53be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.append(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81052eb2",
   "metadata": {},
   "source": [
    "Теперь поиграем с количеством скрытых слоев и запишем результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4951f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [2, 3, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa454688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count hidden layers: 2\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "metric=12.062669596245446\n",
      "Count hidden layers: 3\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "metric=12.805922751317889\n",
      "Count hidden layers: 5\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "metric=13.735003635058144\n",
      "Count hidden layers: 10\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "metric=13.261596092041827\n"
     ]
    }
   ],
   "source": [
    "for layer in layers:\n",
    "    params.append({\"layers\": layer, \"hiddenLayersNeurons\": 256, \"hiddenLayersFunc\": \"relu\", \"optimizer\": \"Adam\"})\n",
    "    print(f\"Count hidden layers: {layer}\")\n",
    "    \n",
    "    model = Sequential(name='test_model')\n",
    "    model.add( Dense( 128, activation='linear', input_shape=(13,))) \n",
    "    \n",
    "    for index in range(layer):\n",
    "        model.add( Dense( 256, activation='relu')) \n",
    "    \n",
    "    model.add( Dense(1))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(), \n",
    "        loss='mse', \n",
    "        metrics=[RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=100, verbose = 0)\n",
    "    \n",
    "    y_predict = model.predict(X_test)\n",
    "    \n",
    "    metric = rmse(y_test, y_predict).numpy()\n",
    "    print(f\"{metric=}\")\n",
    "    \n",
    "    metrics.append(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00497694",
   "metadata": {},
   "source": [
    "Лучше всех показала себя сеть с 2 скрытыми слоям, продолжим исследование с ней. Теперь попробуем поменять число нейронов на скрытых слоях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88c10439",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = [64, 128, 384, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94198b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count neurons on hidden layers: 64\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "metric=12.918452325747097\n",
      "Count neurons on hidden layers: 128\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "metric=12.849934156055932\n",
      "Count neurons on hidden layers: 384\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "metric=13.353689541961682\n",
      "Count neurons on hidden layers: 512\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "metric=12.62412966268529\n"
     ]
    }
   ],
   "source": [
    "for neuron in neurons:\n",
    "    params.append({\"layers\": 2, \"hiddenLayersNeurons\": neuron, \"hiddenLayersFunc\": \"relu\", \"optimizer\": \"Adam\"})\n",
    "    print(f\"Count neurons on hidden layers: {neuron}\")\n",
    "    \n",
    "    model = Sequential(name='test_model')\n",
    "    model.add( Dense( 128, activation='linear', input_shape=(13,))) \n",
    "    \n",
    "    model.add( Dense( neuron, activation='relu')) \n",
    "    model.add( Dense( neuron, activation='relu')) \n",
    "    \n",
    "    model.add( Dense(1))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(), \n",
    "        loss='mse', \n",
    "        metrics=[RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=100, verbose = 0)\n",
    "    \n",
    "    y_predict = model.predict(X_test)\n",
    "    \n",
    "    metric = rmse(y_test, y_predict).numpy()\n",
    "    print(f\"{metric=}\")\n",
    "    \n",
    "    metrics.append(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d152d7ee",
   "metadata": {},
   "source": [
    "На данном этапе лучше всего себя показала модель с 512 нейронами. Зафиксируем этот параметр и перейдем к экспериментам с функцией активации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f596440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = [\"linear\", \"sigmoid\", \"tanh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49e6d062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func on hidden layers: linear\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "metric=13.98342152442655\n",
      "Func on hidden layers: sigmoid\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "metric=11.922854903563541\n",
      "Func on hidden layers: tanh\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "metric=11.555270103538502\n"
     ]
    }
   ],
   "source": [
    "for func in funcs:\n",
    "    params.append({\"layers\": 2, \"hiddenLayersNeurons\": 512, \"hiddenLayersFunc\": func, \"optimizer\": \"Adam\"})\n",
    "    print(f\"Func on hidden layers: {func}\")\n",
    "    \n",
    "    model = Sequential(name='test_model')\n",
    "    model.add( Dense( 128, activation='linear', input_shape=(13,))) \n",
    "    \n",
    "    model.add( Dense( 512, activation=func)) \n",
    "    model.add( Dense( 512, activation=func)) \n",
    "    \n",
    "    model.add( Dense(1))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(), \n",
    "        loss='mse', \n",
    "        metrics=[RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=100, verbose = 0)\n",
    "    \n",
    "    y_predict = model.predict(X_test)\n",
    "    \n",
    "    metric = rmse(y_test, y_predict).numpy()\n",
    "    print(f\"{metric=}\")\n",
    "    \n",
    "    metrics.append(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466bf474",
   "metadata": {},
   "source": [
    "Лучше всех показала себя модель с функцией активации tanh, зафиксируем этот параметр и поэксперементируем с функцией оптимизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d23b551",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = [\"SGD\", \"RMSprop\", \"Adagrad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c949c7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer: SGD\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "metric=nan\n",
      "Optimizer: RMSprop\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "metric=11.561908638852827\n",
      "Optimizer: Adagrad\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "metric=11.258166620940317\n"
     ]
    }
   ],
   "source": [
    "for optimizer in optimizers:\n",
    "    params.append({\"layers\": 2, \"hiddenLayersNeurons\": 512, \"hiddenLayersFunc\": \"tanh\", \"optimizer\": optimizer})\n",
    "    print(f\"Optimizer: {optimizer}\")\n",
    "    \n",
    "    model = Sequential(name='test_model')\n",
    "    model.add( Dense( 128, activation='linear', input_shape=(13,))) \n",
    "    \n",
    "    model.add( Dense( 512, activation=\"tanh\")) \n",
    "    model.add( Dense( 512, activation=\"tanh\")) \n",
    "    \n",
    "    model.add( Dense(1))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer, \n",
    "        loss='mse', \n",
    "        metrics=[RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=100, verbose = 0)\n",
    "    \n",
    "    y_predict = model.predict(X_test)\n",
    "    \n",
    "    metric = rmse(y_test, y_predict).numpy()\n",
    "    print(f\"{metric=}\")\n",
    "    \n",
    "    metrics.append(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef0fb80",
   "metadata": {},
   "source": [
    "Теперь можем вывести все данные в одну таблицу и провести анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a94e80b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99dbe5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Количество слоев</th><th>Количествой нейронов</th><th>Функция активации</th><th>Функция активизации</th><th>Метрика</th></tr><tr><td>1</td><td>256</td><td>relu</td><td>Adam</td><td>11.77192442137926</td></tr><tr><td>2</td><td>256</td><td>relu</td><td>Adam</td><td>12.062669596245446</td></tr><tr><td>3</td><td>256</td><td>relu</td><td>Adam</td><td>12.805922751317889</td></tr><tr><td>5</td><td>256</td><td>relu</td><td>Adam</td><td>13.735003635058144</td></tr><tr><td>10</td><td>256</td><td>relu</td><td>Adam</td><td>13.261596092041827</td></tr><tr><td>2</td><td>64</td><td>relu</td><td>Adam</td><td>12.918452325747097</td></tr><tr><td>2</td><td>128</td><td>relu</td><td>Adam</td><td>12.849934156055932</td></tr><tr><td>2</td><td>384</td><td>relu</td><td>Adam</td><td>13.353689541961682</td></tr><tr><td>2</td><td>512</td><td>relu</td><td>Adam</td><td>12.62412966268529</td></tr><tr><td>2</td><td>512</td><td>linear</td><td>Adam</td><td>13.98342152442655</td></tr><tr><td>2</td><td>512</td><td>sigmoid</td><td>Adam</td><td>11.922854903563541</td></tr><tr><td>2</td><td>512</td><td>tanh</td><td>Adam</td><td>11.555270103538502</td></tr><tr><td>2</td><td>512</td><td>tanh</td><td>SGD</td><td>nan</td></tr><tr><td>2</td><td>512</td><td>tanh</td><td>RMSprop</td><td>11.561908638852827</td></tr><tr><td>2</td><td>512</td><td>tanh</td><td>Adagrad</td><td>11.258166620940317</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def dataToTable(params, metrics, columns):\n",
    "    hdr = ''\n",
    "    \n",
    "    for col in columns:\n",
    "        hdr = hdr + '<th>' + col + '</th>'\n",
    "    \n",
    "    hdr = '<tr>' + hdr + '</tr>'\n",
    "\n",
    "    dt = ''\n",
    "    \n",
    "    for index in range(len(params)):\n",
    "        param = params[index]\n",
    "        metric = metrics[index]\n",
    "        \n",
    "        dt = dt + '<tr>'\n",
    "        \n",
    "        dt = dt + '<td>' + str(param[\"layers\"])+ '</td>'\n",
    "        dt = dt + '<td>' + str(param[\"hiddenLayersNeurons\"])+ '</td>'\n",
    "        dt = dt + '<td>' + param[\"hiddenLayersFunc\"]+ '</td>'\n",
    "        dt = dt + '<td>' + param[\"optimizer\"]+ '</td>'\n",
    "        dt = dt + '<td>' + str(metric) + '</td>'\n",
    "            \n",
    "        dt = dt + '</tr>'\n",
    "            \n",
    "    display(HTML('<table>' + hdr + dt + '</table>'))\n",
    "\n",
    "dataToTable(params, metrics, columns=[\"Количество слоев\",\"Количествой нейронов\", \"Функция активации\", \"Функция активизации\", \"Метрика\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf32797",
   "metadata": {},
   "source": [
    "Из таблицы можно сделать вывод что более сильное влияние на модель оказывает количество слоев и тут нельзя переборщить, наших данных не так много.\n",
    "\n",
    "Количество нейронов в скрытых слоях не сильно влияют на модель, возможно в будующих исследованиях надо пробовать делать их разным на каждом слое.\n",
    "\n",
    "Лучше всех себя показала функция активации **tanh**, но тут так же можно проводить экспиременты с разными функциями активации\n",
    "\n",
    "Функцию оптимизации SGD. лучше не использовать, она не работает на этих данных. А лучше всех подходит **Adagrad**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
